{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train\n",
    "\n",
    "Algoritmi:\n",
    "\n",
    "**K-Nearest Neighbors (KNN)**:\n",
    "Pro: Semplice da implementare, non richiede addestramento costoso.\n",
    "Contro: Prestazioni possono decadere con dataset di grandi dimensioni. Sensibile alla scala delle feature.\n",
    "\n",
    "**Decision Trees**:\n",
    "Pro: Facile da interpretare, gestisce automaticamente le feature rilevanti.\n",
    "Contro: Tendenza all'overfitting. Può essere instabile con piccole variazioni nei dati.\n",
    "\n",
    "**Linear Regression**:\n",
    "Pro: Semplice e interpretabile, adatta per relazioni lineari tra feature e target.\n",
    "Contro: Sensibile a outliers. Non gestisce bene relazioni complesse.\n",
    "\n",
    "**Logistic Regression**:\n",
    "Pro: Buona per problemi di classificazione binaria.\n",
    "Contro: Assume una relazione lineare tra le feature e il log-odds. Non gestisce bene relazioni complesse.\n",
    "\n",
    "**Support Vector Machines (SVM)**:\n",
    "Pro: Buone prestazioni in spazi delle feature ad alta dimensione.\n",
    "Contro: Richiede una scelta accurata dei parametri. Non sempre efficace con dataset molto grandi.\n",
    "\n",
    "**Random Forest**:\n",
    "Pro: Buona capacità di gestire complessità e overfitting. Può fornire importanza delle feature.\n",
    "Contro: Meno interpretabile rispetto ai singoli alberi. Può richiedere tempo per l'addestramento.\n",
    "\n",
    "**Ensemble Methods**:\n",
    "Pro: Combina diversi modelli per migliorare le prestazioni complessive.\n",
    "Contro: Complessità e interpretabilità possono essere un problema.\n",
    "\n",
    "**Neural Networks**:\n",
    "Pro: Eccellenti per problemi complessi e non lineari. Addestramento su grandi quantità di dati.\n",
    "Contro: Richiede molto dati e risorse di calcolo. Complessità nella scelta dell'architettura.\n",
    "\n",
    "**Convolutional Neural Networks (CNN)**:\n",
    "Pro: Eccellenti per dati strutturati come immagini. Applicabili anche a dati sequenziali.\n",
    "Contro: Richiede dati etichettati in grandi quantità.\n",
    "\n",
    "Escludiamo quindi Linear Regression, Decision Trees,Support Vector Machines (SVM) e Convolutional Neural Networks (CNN).\n",
    "\n",
    "Considerazioni:\n",
    "\n",
    "Possiamo utilizzare i rimanenti algoritmi per dividere il problema il 4 categorie: Unsafe, Target 1 day, Target 5 days, Target 30 days.\n",
    "\n",
    "**Knn**:\n",
    "La scelta del K è importante e può variare molto prendendo due K molto vicini.\n",
    "Per questo motivo abbiamo deciso di affidarci ad altri tipi di algoritmi per questo tipo di problema.\n",
    " \n",
    "**Logistic Regression**: \n",
    "Possiamo utilizzare la Regressione Logistica per dividere il problema in 3 sottoproblemi. Possiamo classificare se le predizioni appartengono o meno all'etichetta Target 1 day, Target 5 days o Target 30 days. Se tutte e 3 dovessero essere 0, la scelta ricadrebbe su Unsafe.\n",
    "Questo vorrebbe dire allenare 3 volte l'algoritmo predicendo una alla volta tutte e tre le etichette.\n",
    "(Da testare)\n",
    "\n",
    "**Random Forests**:\n",
    "Possiamo utilizzare la tecnica del Bagging per ridurre la varianza, tipicamente elevata con questo algoritmo, per avere un accuracy più alta.\n",
    "(Da testare)\n",
    "\n",
    "**Ensemble Methods**: \n",
    "(Che metodi utilizzare?)\n",
    "(Da Testare)\n",
    "\n",
    "**Neural Networks**: \n",
    "L'utilizzo delle neural networks risulta essere più complicato degli altri poiché è più difficile da costruire e può svilupparsi in diverse varianti.\n",
    "La parte difficile appunto sta nella scelta del numero di hidden layers e nel numero di nodi di questi. Tale scelta può essere affinata con test ripetuti per arrivare ad una soluzione comune.\n",
    "(Da testare)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28918e1ed52316e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc15b3fd4a850708"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:29:04.994073Z",
     "start_time": "2023-11-23T15:29:04.950703Z"
    }
   },
   "id": "45384eb0b2c9c55a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "            Date          Open          High           Low         Close  \\\n0     2020-06-30  90534.565179  90717.278731  89255.570312  89255.570312   \n1     2020-07-01  89986.421883  90899.989618  89529.638016  89712.351562   \n2     2020-07-02  89529.635417  91082.700521  89529.635417  90443.203125   \n3     2020-07-03  91265.419308  91813.559964  90077.781218  90625.921875   \n4     2020-07-06  91082.695405  93640.684845  90260.484514  92727.117188   \n...          ...           ...           ...           ...           ...   \n26675 2023-10-20    112.919998    113.320000    110.790001    111.080002   \n26676 2023-10-23    110.629997    110.959999    108.680000    109.449997   \n26677 2023-10-24    109.699997    109.820000    108.120003    108.389999   \n26678 2023-10-25    108.519997    109.500000    108.129997    108.589996   \n26679 2023-10-26    107.449997    108.339996    106.495003    107.425003   \n\n         Volume  Dividends  Stock Splits  Daily_Return  Target_1day  ...  \\\n0        988987        0.0           0.0      0.000000            1  ...   \n1        640540        0.0           0.0      0.005118            1  ...   \n2        730963        0.0           0.0      0.008147            1  ...   \n3        569575        0.0           0.0      0.002020            1  ...   \n4       1189877        0.0           0.0      0.023185            0  ...   \n...         ...        ...           ...           ...          ...  ...   \n26675  22439800        0.0           0.0     -0.017165            0  ...   \n26676  18185000        0.0           0.0     -0.014674            0  ...   \n26677  16786100        0.0           0.0     -0.009685            1  ...   \n26678  22047300        0.0           0.0      0.001845            0  ...   \n26679  12054832        0.0           0.0     -0.010728            0  ...   \n\n              MA_30         MA_50        RSI        MACD  Signal_Line  \\\n0      92851.977604  89900.544844  29.090917 -314.945626   517.337196   \n1      92879.384896  89858.520781  33.114757 -434.587634   326.952230   \n2      92934.198698  89884.100625  41.444863 -465.070135   168.547757   \n3      93077.324479  89988.247500  55.500008 -469.076637    41.022878   \n4      93244.811979  90150.862500  50.000000 -299.253312   -27.032360   \n...             ...           ...        ...         ...          ...   \n26675    113.866000    112.431415  41.095898   -0.672795    -0.697816   \n26676    113.709000    112.402000  38.176416   -0.775562    -0.713365   \n26677    113.405666    112.349600  43.441582   -0.931798    -0.757052   \n26678    113.143999    112.358200  49.065416   -1.027632    -0.811168   \n26679    112.774166    112.379900  50.614618   -1.183938    -0.885722   \n\n       Bollinger_Mid_Band  Bollinger_Upper_Band  Bollinger_Lower_Band  \\\n0            94577.098437         104488.275493          84665.921382   \n1            94106.611328         104003.310201          84209.912455   \n2            93672.666797         103409.739151          83935.594443   \n3            93133.661719         102267.155198          84000.168239   \n4            92608.360156         100464.250846          84752.469466   \n...                   ...                   ...                   ...   \n26675          112.580000            120.644831            104.515168   \n26676          112.240999            120.232491            104.249507   \n26677          111.839999            119.758208            103.921790   \n26678          111.259499            118.283746            104.235252   \n26679          110.657249            116.757753            104.556745   \n\n       Volatility    Ticker  \n0        0.030295  005380KS  \n1        0.018542  005380KS  \n2        0.012799  005380KS  \n3        0.012387  005380KS  \n4        0.009195  005380KS  \n...           ...       ...  \n26675    0.012627       XOM  \n26676    0.014787       XOM  \n26677    0.012802       XOM  \n26678    0.008695       XOM  \n26679    0.007316       XOM  \n\n[26680 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Dividends</th>\n      <th>Stock Splits</th>\n      <th>Daily_Return</th>\n      <th>Target_1day</th>\n      <th>...</th>\n      <th>MA_30</th>\n      <th>MA_50</th>\n      <th>RSI</th>\n      <th>MACD</th>\n      <th>Signal_Line</th>\n      <th>Bollinger_Mid_Band</th>\n      <th>Bollinger_Upper_Band</th>\n      <th>Bollinger_Lower_Band</th>\n      <th>Volatility</th>\n      <th>Ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-30</td>\n      <td>90534.565179</td>\n      <td>90717.278731</td>\n      <td>89255.570312</td>\n      <td>89255.570312</td>\n      <td>988987</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>...</td>\n      <td>92851.977604</td>\n      <td>89900.544844</td>\n      <td>29.090917</td>\n      <td>-314.945626</td>\n      <td>517.337196</td>\n      <td>94577.098437</td>\n      <td>104488.275493</td>\n      <td>84665.921382</td>\n      <td>0.030295</td>\n      <td>005380KS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-07-01</td>\n      <td>89986.421883</td>\n      <td>90899.989618</td>\n      <td>89529.638016</td>\n      <td>89712.351562</td>\n      <td>640540</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.005118</td>\n      <td>1</td>\n      <td>...</td>\n      <td>92879.384896</td>\n      <td>89858.520781</td>\n      <td>33.114757</td>\n      <td>-434.587634</td>\n      <td>326.952230</td>\n      <td>94106.611328</td>\n      <td>104003.310201</td>\n      <td>84209.912455</td>\n      <td>0.018542</td>\n      <td>005380KS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-07-02</td>\n      <td>89529.635417</td>\n      <td>91082.700521</td>\n      <td>89529.635417</td>\n      <td>90443.203125</td>\n      <td>730963</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.008147</td>\n      <td>1</td>\n      <td>...</td>\n      <td>92934.198698</td>\n      <td>89884.100625</td>\n      <td>41.444863</td>\n      <td>-465.070135</td>\n      <td>168.547757</td>\n      <td>93672.666797</td>\n      <td>103409.739151</td>\n      <td>83935.594443</td>\n      <td>0.012799</td>\n      <td>005380KS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-07-03</td>\n      <td>91265.419308</td>\n      <td>91813.559964</td>\n      <td>90077.781218</td>\n      <td>90625.921875</td>\n      <td>569575</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.002020</td>\n      <td>1</td>\n      <td>...</td>\n      <td>93077.324479</td>\n      <td>89988.247500</td>\n      <td>55.500008</td>\n      <td>-469.076637</td>\n      <td>41.022878</td>\n      <td>93133.661719</td>\n      <td>102267.155198</td>\n      <td>84000.168239</td>\n      <td>0.012387</td>\n      <td>005380KS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-07-06</td>\n      <td>91082.695405</td>\n      <td>93640.684845</td>\n      <td>90260.484514</td>\n      <td>92727.117188</td>\n      <td>1189877</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.023185</td>\n      <td>0</td>\n      <td>...</td>\n      <td>93244.811979</td>\n      <td>90150.862500</td>\n      <td>50.000000</td>\n      <td>-299.253312</td>\n      <td>-27.032360</td>\n      <td>92608.360156</td>\n      <td>100464.250846</td>\n      <td>84752.469466</td>\n      <td>0.009195</td>\n      <td>005380KS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26675</th>\n      <td>2023-10-20</td>\n      <td>112.919998</td>\n      <td>113.320000</td>\n      <td>110.790001</td>\n      <td>111.080002</td>\n      <td>22439800</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.017165</td>\n      <td>0</td>\n      <td>...</td>\n      <td>113.866000</td>\n      <td>112.431415</td>\n      <td>41.095898</td>\n      <td>-0.672795</td>\n      <td>-0.697816</td>\n      <td>112.580000</td>\n      <td>120.644831</td>\n      <td>104.515168</td>\n      <td>0.012627</td>\n      <td>XOM</td>\n    </tr>\n    <tr>\n      <th>26676</th>\n      <td>2023-10-23</td>\n      <td>110.629997</td>\n      <td>110.959999</td>\n      <td>108.680000</td>\n      <td>109.449997</td>\n      <td>18185000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.014674</td>\n      <td>0</td>\n      <td>...</td>\n      <td>113.709000</td>\n      <td>112.402000</td>\n      <td>38.176416</td>\n      <td>-0.775562</td>\n      <td>-0.713365</td>\n      <td>112.240999</td>\n      <td>120.232491</td>\n      <td>104.249507</td>\n      <td>0.014787</td>\n      <td>XOM</td>\n    </tr>\n    <tr>\n      <th>26677</th>\n      <td>2023-10-24</td>\n      <td>109.699997</td>\n      <td>109.820000</td>\n      <td>108.120003</td>\n      <td>108.389999</td>\n      <td>16786100</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.009685</td>\n      <td>1</td>\n      <td>...</td>\n      <td>113.405666</td>\n      <td>112.349600</td>\n      <td>43.441582</td>\n      <td>-0.931798</td>\n      <td>-0.757052</td>\n      <td>111.839999</td>\n      <td>119.758208</td>\n      <td>103.921790</td>\n      <td>0.012802</td>\n      <td>XOM</td>\n    </tr>\n    <tr>\n      <th>26678</th>\n      <td>2023-10-25</td>\n      <td>108.519997</td>\n      <td>109.500000</td>\n      <td>108.129997</td>\n      <td>108.589996</td>\n      <td>22047300</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.001845</td>\n      <td>0</td>\n      <td>...</td>\n      <td>113.143999</td>\n      <td>112.358200</td>\n      <td>49.065416</td>\n      <td>-1.027632</td>\n      <td>-0.811168</td>\n      <td>111.259499</td>\n      <td>118.283746</td>\n      <td>104.235252</td>\n      <td>0.008695</td>\n      <td>XOM</td>\n    </tr>\n    <tr>\n      <th>26679</th>\n      <td>2023-10-26</td>\n      <td>107.449997</td>\n      <td>108.339996</td>\n      <td>106.495003</td>\n      <td>107.425003</td>\n      <td>12054832</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.010728</td>\n      <td>0</td>\n      <td>...</td>\n      <td>112.774166</td>\n      <td>112.379900</td>\n      <td>50.614618</td>\n      <td>-1.183938</td>\n      <td>-0.885722</td>\n      <td>110.657249</td>\n      <td>116.757753</td>\n      <td>104.556745</td>\n      <td>0.007316</td>\n      <td>XOM</td>\n    </tr>\n  </tbody>\n</table>\n<p>26680 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.ExcelFile('final_dataset.xlsx').parse('Sheet1')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:49:46.825131Z",
     "start_time": "2023-11-23T14:49:38.520645Z"
    }
   },
   "id": "956e36475c7e88af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Knn\n",
    "\n",
    "Dobbiamo convertire tutte le feature in float per poter utilizzare l'algoritmo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbe8fe2d4d40732f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Converti date in float\n",
    "df['Date'] = pd.to_datetime(df['Date']).astype(int) / 10**9\n",
    "df['Ticker'] = pd.factorize(df.Ticker)[0]\n",
    "df['Volume'] = df['Volume'].astype(float)\n",
    "df['Target_1day'] = df['Target_1day'].astype(float)\n",
    "df['Target_5days'] = df['Target_5days'].astype(float)\n",
    "df['Target_30days'] = df['Target_30days'].astype(float)\n",
    "df['Net Income'] = df['Net Income'].astype(float)\n",
    "df['Total Revenue'] = df['Total Revenue'].astype(float)\n",
    "df['Normalized EBITDA'] = df['Normalized EBITDA'].astype(float)\n",
    "df['Total Unusual Items'] = df['Total Unusual Items'].astype(float)\n",
    "df['Total Unusual Items Excluding Goodwill'] = df['Total Unusual Items Excluding Goodwill'].astype(float)\n",
    "df['Operating Cash Flow'] = df['Operating Cash Flow'].astype(float)\n",
    "df['Capital Expenditure'] = df['Capital Expenditure'].astype(float)\n",
    "df['Free Cash Flow'] = df['Free Cash Flow'].astype(float)\n",
    "df['Cash Flow From Continuing Operating Activities'] = df['Cash Flow From Continuing Operating Activities'].astype(float)\n",
    "df['Cash Flow From Continuing Investing Activities'] = df['Cash Flow From Continuing Investing Activities'].astype(float)\n",
    "df['Cash Flow From Continuing Financing Activities'] = df['Cash Flow From Continuing Financing Activities'].astype(float)\n",
    "df['Ticker'] = df['Ticker'].astype(float)\n",
    "\n",
    "# divide test and train\n",
    "X = df.drop(['Target_1day', 'Target_5days', 'Target_30days'], axis=1)\n",
    "Y = df[['Target_1day', 'Target_5days', 'Target_30days']]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:50:45.766804Z",
     "start_time": "2023-11-23T14:50:45.726019Z"
    }
   },
   "id": "62674f7923e6c357"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KNN with K = 1 is 0.3779985007496252\n",
      "Accuracy for KNN with K = 3 is 0.35344827586206895\n",
      "Accuracy for KNN with K = 5 is 0.30603448275862066\n",
      "Accuracy for KNN with K = 7 is 0.3154047976011994\n",
      "Accuracy for KNN with K = 9 is 0.30359820089955025\n",
      "Accuracy for KNN with K = 11 is 0.29685157421289354\n",
      "Accuracy for KNN with K = 13 is 0.2946026986506747\n",
      "Accuracy for KNN with K = 15 is 0.2912293853073463\n",
      "Accuracy for KNN with K = 17 is 0.2901049475262369\n",
      "Accuracy for KNN with K = 19 is 0.28523238380809596\n",
      "Accuracy for KNN with K = 21 is 0.2848575712143928\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for i in [1,3,5,7,9,11,13,15,17,19,21]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict(X_test)\n",
    "    print(\"Accuracy for KNN with K = \" + str(i) + \" is \" + str(accuracy_score(Y_test, Y_pred)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:50:56.636106Z",
     "start_time": "2023-11-23T14:50:46.925725Z"
    }
   },
   "id": "2e260f77946702c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7c7e8e97b2f33dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Importiamo il dataset con i dati originali\n",
    "df = pd.ExcelFile('final_dataset.xlsx').parse('Sheet1')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "667086e4054bf4f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dividiamo il nostro problema di classificazione in 3 sottoproblemi:\n",
    "\n",
    "- X_1 e Y_1: Target_1day\n",
    "- X_2 e Y_2: Target_5days\n",
    "- X_3 e Y_3: Target_30days\n",
    "\n",
    "In questo modo per ogni sottoproblema possiamo allenare un modello di regressione logistica per classificare se una predizione appartiene o meno all'etichetta."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e8a602c26a3fd60"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_1 = df.drop('Target_1day', axis=1)\n",
    "Y_1 = df['Target_1day']\n",
    "\n",
    "X_train_1_80, X_test_1, Y_train_1_80, Y_test_1 = train_test_split(X_1, Y_1, test_size=0.2)\n",
    "X_train_1, X_valid_1, Y_train_1, Y_valid_1 = train_test_split(X_train_1_80, Y_train_1_80, test_size=0.20)\n",
    "\n",
    "X_2 = df.drop('Target_5days', axis=1)\n",
    "Y_2 = df['Target_5days']\n",
    "\n",
    "X_train_2_80, X_test_2, Y_train_2_80, Y_test_2 = train_test_split(X_2, Y_2, test_size=0.2)\n",
    "X_valid_2, X_train_2, Y_valid_2, Y_train_2 = train_test_split(X_train_2_80, Y_train_2_80, test_size=0.20)\n",
    "\n",
    "X_3 = df.drop('Target_30days', axis=1)\n",
    "Y_3 = df['Target_30days']\n",
    "\n",
    "X_train_3_80, X_test_3, Y_train_3_80, Y_test_3 = train_test_split(X_3, Y_3, test_size=0.2)\n",
    "X_valid_3, X_train_3, Y_valid_3, Y_train_3 = train_test_split(X_train_3_80, Y_train_3_80, test_size=0.20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:42:59.067765Z",
     "start_time": "2023-11-23T15:42:58.997358Z"
    }
   },
   "id": "4b462dcee02cc58b"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 1: 0.51\n",
      "Validation set 1: 0.51\n",
      "Test set 1: 0.51\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_1, Y_train_1)\n",
    "train_acc = accuracy_score(y_true= Y_train_1, y_pred= logreg.predict(X_train_1))\n",
    "scores = cross_val_score(logreg, X_train_1_80, Y_train_1_80, \n",
    "                         cv=5, scoring='accuracy', \n",
    "                         verbose = 0)\n",
    "print(\"Train set 1: {:.2f}\".format(train_acc))\n",
    "print('Validation set 1: {:.2f}'.format(scores.mean()))\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_1_80, Y_train_1_80)\n",
    "test_acc = accuracy_score(y_true= Y_test_1, y_pred= logreg.predict(X_test_1))\n",
    "\n",
    "print('Test set 1: {:.2f}'.format(test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:43:00.811436Z",
     "start_time": "2023-11-23T15:42:59.801785Z"
    }
   },
   "id": "4b28c56c224183ad"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/General/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/General/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/General/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 2: 0.50\n",
      "Validation set 2: 0.51\n",
      "Test set 2: 0.51\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_2, Y_train_2)\n",
    "train_acc = accuracy_score(y_true= Y_train_2, y_pred= logreg.predict(X_train_2))\n",
    "scores = cross_val_score(logreg, X_train_2_80, Y_train_2_80, \n",
    "                         cv=5, scoring='accuracy', \n",
    "                         verbose = 0)\n",
    "print(\"Train set 2: {:.2f}\".format(train_acc))\n",
    "print('Validation set 2: {:.2f}'.format(scores.mean()))\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_2_80, Y_train_2_80)\n",
    "test_acc = accuracy_score(y_true= Y_test_2, y_pred= logreg.predict(X_test_2))\n",
    "\n",
    "print('Test set 2: {:.2f}'.format(test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:43:04.257854Z",
     "start_time": "2023-11-23T15:43:02.420469Z"
    }
   },
   "id": "1b8c2c1491f788d7"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/General/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/General/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/General/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/General/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/General/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 3: 0.54\n",
      "Validation set 3: 0.51\n",
      "Test set 3: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/General/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_3, Y_train_3)\n",
    "train_acc = accuracy_score(y_true= Y_train_3, y_pred= logreg.predict(X_train_3))\n",
    "scores = cross_val_score(logreg, X_train_3_80, Y_train_3_80, \n",
    "                         cv=5, scoring='accuracy', \n",
    "                         verbose = 0)\n",
    "print(\"Train set 3: {:.2f}\".format(train_acc))\n",
    "print('Validation set 3: {:.2f}'.format(scores.mean()))\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_3_80, Y_train_3_80)\n",
    "test_acc = accuracy_score(y_true= Y_test_3, y_pred= logreg.predict(X_test_3))\n",
    "\n",
    "print('Test set 3: {:.2f}'.format(test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:43:09.889146Z",
     "start_time": "2023-11-23T15:43:08.056182Z"
    }
   },
   "id": "3348c63a4ce6a822"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14e0c48d2f64de1"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth: 2\n",
      "Train set 1: 0.65\n",
      "Validation set 1: 0.64\n",
      "\n",
      "Train set 2: 0.68\n",
      "Validation set 2: 0.65\n",
      "\n",
      "Train set 3: 0.65\n",
      "Validation set 3: 0.65\n",
      "\n",
      "\n",
      "Max depth: 10\n",
      "Train set 1: 0.67\n",
      "Validation set 1: 0.65\n",
      "\n",
      "Train set 2: 0.86\n",
      "Validation set 2: 0.70\n",
      "\n",
      "Train set 3: 0.91\n",
      "Validation set 3: 0.81\n",
      "\n",
      "\n",
      "Max depth: 30\n",
      "Train set 1: 1.00\n",
      "Validation set 1: 0.62\n",
      "\n",
      "Train set 2: 1.00\n",
      "Validation set 2: 0.75\n",
      "\n",
      "Train set 3: 1.00\n",
      "Validation set 3: 0.91\n",
      "\n",
      "\n",
      "Max depth: 50\n",
      "Train set 1: 1.00\n",
      "Validation set 1: 0.61\n",
      "\n",
      "Train set 2: 1.00\n",
      "Validation set 2: 0.75\n",
      "\n",
      "Train set 3: 1.00\n",
      "Validation set 3: 0.91\n",
      "\n",
      "\n",
      "Max depth: 70\n",
      "Train set 1: 1.00\n",
      "Validation set 1: 0.61\n",
      "\n",
      "Train set 2: 1.00\n",
      "Validation set 2: 0.75\n",
      "\n",
      "Train set 3: 1.00\n",
      "Validation set 3: 0.91\n",
      "\n",
      "\n",
      "Max depth: 100\n",
      "Train set 1: 1.00\n",
      "Validation set 1: 0.61\n",
      "\n",
      "Train set 2: 1.00\n",
      "Validation set 2: 0.75\n",
      "\n",
      "Train set 3: 1.00\n",
      "Validation set 3: 0.91\n",
      "\n",
      "\n",
      "Max depth: 500\n",
      "Train set 1: 1.00\n",
      "Validation set 1: 0.61\n",
      "\n",
      "Train set 2: 1.00\n",
      "Validation set 2: 0.76\n",
      "\n",
      "Train set 3: 1.00\n",
      "Validation set 3: 0.91\n",
      "\n",
      "\n",
      "Max depth: 1000\n",
      "Train set 1: 1.00\n",
      "Validation set 1: 0.61\n",
      "\n",
      "Train set 2: 1.00\n",
      "Validation set 2: 0.75\n",
      "\n",
      "Train set 3: 1.00\n",
      "Validation set 3: 0.91\n",
      "\n",
      "\n",
      "Best max depth: 30\n",
      "Test set 1: 0.61\n",
      "Test set 2: 0.76\n",
      "Test set 3: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "best_i = []\n",
    "for i in [2,10,30,50,70,100,500,1000]:\n",
    "    print('Max depth: ' + str(i) + '\\n')\n",
    "    \n",
    "    # Target 1 day\n",
    "    rm_1 = RandomForestClassifier(max_depth=i)\n",
    "    rm_1.fit(X_train_1, Y_train_1)\n",
    "    train_acc_1 = accuracy_score(y_true= Y_train_1, y_pred= rm_1.predict(X_train_1))\n",
    "    scores_1 = cross_val_score(rm_1, X_train_1_80, Y_train_1_80, \n",
    "                             cv=5, scoring='accuracy', \n",
    "                             verbose = 0)\n",
    "    print(\"Train set 1: {:.2f}\".format(train_acc_1))\n",
    "    print('Validation set 1: {:.2f}'.format(scores_1.mean()))\n",
    "    print('\\n')\n",
    "    # Target 5 days\n",
    "    rm_2 = RandomForestClassifier(max_depth=i)\n",
    "    rm_2.fit(X_train_2, Y_train_2)\n",
    "    train_acc_2 = accuracy_score(y_true= Y_train_2, y_pred= rm_2.predict(X_train_2))\n",
    "    scores_2 = cross_val_score(rm_2, X_train_2_80, Y_train_2_80, \n",
    "                             cv=5, scoring='accuracy', \n",
    "                             verbose = 0)\n",
    "    print(\"Train set 2: {:.2f}\".format(train_acc_2))\n",
    "    print('Validation set 2: {:.2f}'.format(scores_2.mean()))\n",
    "    print('\\n')\n",
    "    # Target 30 days\n",
    "    rm_3 = RandomForestClassifier(max_depth=i)\n",
    "    rm_3.fit(X_train_3, Y_train_3)\n",
    "    train_acc_3 = accuracy_score(y_true= Y_train_3, y_pred= rm_3.predict(X_train_3))\n",
    "    scores_3 = cross_val_score(rm_3, X_train_3_80, Y_train_3_80, \n",
    "                             cv=5, scoring='accuracy', \n",
    "                             verbose = 0)\n",
    "    print(\"Train set 3: {:.2f}\".format(train_acc_3))\n",
    "    print('Validation set 3: {:.2f}'.format(scores_3.mean()))\n",
    "    print('\\n')\n",
    "    \n",
    "    best_i.append([i, scores_1.mean() + scores_2.mean() + scores_3.mean()])\n",
    "    \n",
    "    \n",
    "i = max(best_i, key=lambda x:x[1])[0]\n",
    "print('Best max depth: ' + str(i) + '\\n')\n",
    "# Target 1 day\n",
    "rm_1 = RandomForestClassifier(max_depth=i)\n",
    "rm_1.fit(X_train_1_80, Y_train_1_80)\n",
    "test_acc_1 = accuracy_score(y_true= Y_test_1, y_pred= rm_1.predict(X_test_1))\n",
    "print('Test set 1: {:.2f}'.format(test_acc_1))\n",
    "\n",
    "# Target 5 days\n",
    "rm_2 = RandomForestClassifier(max_depth=i)\n",
    "rm_2.fit(X_train_2_80, Y_train_2_80)\n",
    "test_acc_2 = accuracy_score(y_true= Y_test_2, y_pred= rm_2.predict(X_test_2))\n",
    "print('Test set 2: {:.2f}'.format(test_acc_2))\n",
    "\n",
    "# Target 30 days\n",
    "rm_3 = RandomForestClassifier(max_depth=i)\n",
    "rm_3.fit(X_train_3_80, Y_train_3_80)\n",
    "test_acc_3 = accuracy_score(y_true= Y_test_3, y_pred= rm_3.predict(X_test_3))\n",
    "print('Test set 3: {:.2f}'.format(test_acc_3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T16:17:25.958291Z",
     "start_time": "2023-11-23T16:03:12.782487Z"
    }
   },
   "id": "f2d1549d2924d5bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Networks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b00188bdb25c44d8"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T16:25:26.615596Z",
     "start_time": "2023-11-23T16:25:26.592189Z"
    }
   },
   "id": "596d1f30215c374"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train 1\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train_1, Y_train_1)\n",
    "Y_pred_1 = clf.predict(X_test_1)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(clf.score(X_test_1, Y_test_1)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T17:43:01.255936Z",
     "start_time": "2023-11-19T17:42:52.645298Z"
    }
   },
   "id": "15f68ab13049667e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.49\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train 2\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train_2, Y_train_2)\n",
    "Y_pred_2 = clf.predict(X_test_2)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(clf.score(X_test_2, Y_test_2)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T17:43:08.830553Z",
     "start_time": "2023-11-19T17:43:01.236410Z"
    }
   },
   "id": "4fccd955ddc82557"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train 3\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train_3, Y_train_3)\n",
    "Y_pred_3 = clf.predict(X_test_3)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(clf.score(X_test_3, Y_test_3)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T17:43:21.921205Z",
     "start_time": "2023-11-19T17:43:08.835080Z"
    }
   },
   "id": "eec02ec6db61406d"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max iter: 100\n",
      "\n",
      "Random state: 1\n",
      "Train set 1: 0.50\n",
      "Validation set 1: 0.50\n",
      "\n",
      "Train set 2: 0.50\n",
      "Validation set 2: 0.50\n",
      "\n",
      "Train set 3: 0.51\n",
      "Validation set 3: 0.52\n",
      "\n",
      "\n",
      "Random state: 7\n",
      "Train set 1: 0.51\n",
      "Validation set 1: 0.51\n",
      "\n",
      "Train set 2: 0.50\n",
      "Validation set 2: 0.50\n",
      "\n",
      "Train set 3: 0.52\n",
      "Validation set 3: 0.51\n",
      "\n",
      "\n",
      "Random state: 10\n",
      "Train set 1: 0.50\n",
      "Validation set 1: 0.50\n",
      "\n",
      "Train set 2: 0.52\n",
      "Validation set 2: 0.51\n",
      "\n",
      "Train set 3: 0.55\n",
      "Validation set 3: 0.52\n",
      "\n",
      "\n",
      "Random state: 20\n",
      "Train set 1: 0.51\n",
      "Validation set 1: 0.50\n",
      "\n",
      "Train set 2: 0.50\n",
      "Validation set 2: 0.50\n",
      "\n",
      "Train set 3: 0.51\n",
      "Validation set 3: 0.53\n",
      "\n",
      "\n",
      "Max iter: 500\n",
      "\n",
      "Random state: 1\n",
      "Train set 1: 0.50\n",
      "Validation set 1: 0.50\n",
      "\n",
      "Train set 2: 0.50\n",
      "Validation set 2: 0.50\n",
      "\n",
      "Train set 3: 0.51\n",
      "Validation set 3: 0.52\n",
      "\n",
      "\n",
      "Random state: 7\n",
      "Train set 1: 0.51\n",
      "Validation set 1: 0.51\n",
      "\n",
      "Train set 2: 0.50\n",
      "Validation set 2: 0.50\n",
      "\n",
      "Train set 3: 0.52\n",
      "Validation set 3: 0.51\n",
      "\n",
      "\n",
      "Random state: 10\n",
      "Train set 1: 0.50\n",
      "Validation set 1: 0.50\n",
      "\n",
      "Train set 2: 0.52\n",
      "Validation set 2: 0.51\n",
      "\n",
      "Train set 3: 0.55\n",
      "Validation set 3: 0.52\n",
      "\n",
      "\n",
      "Random state: 20\n",
      "Train set 1: 0.51\n",
      "Validation set 1: 0.50\n",
      "\n",
      "Train set 2: 0.50\n",
      "Validation set 2: 0.50\n",
      "\n",
      "Train set 3: 0.51\n",
      "Validation set 3: 0.53\n",
      "\n",
      "\n",
      "Max iter: 1000\n",
      "\n",
      "Random state: 1\n",
      "Train set 1: 0.50\n",
      "Validation set 1: 0.50\n",
      "\n",
      "Train set 2: 0.50\n",
      "Validation set 2: 0.50\n",
      "\n",
      "Train set 3: 0.51\n",
      "Validation set 3: 0.52\n",
      "\n",
      "\n",
      "Random state: 7\n",
      "Train set 1: 0.51\n",
      "Validation set 1: 0.51\n",
      "\n",
      "Train set 2: 0.50\n",
      "Validation set 2: 0.50\n",
      "\n",
      "Train set 3: 0.52\n",
      "Validation set 3: 0.51\n",
      "\n",
      "\n",
      "Random state: 10\n",
      "Train set 1: 0.50\n",
      "Validation set 1: 0.50\n",
      "\n",
      "Train set 2: 0.52\n",
      "Validation set 2: 0.51\n",
      "\n",
      "Train set 3: 0.55\n",
      "Validation set 3: 0.52\n",
      "\n",
      "\n",
      "Random state: 20\n",
      "Train set 1: 0.51\n",
      "Validation set 1: 0.50\n",
      "\n",
      "Train set 2: 0.50\n",
      "Validation set 2: 0.50\n",
      "\n",
      "Train set 3: 0.51\n",
      "Validation set 3: 0.53\n",
      "\n",
      "\n",
      "Best max iter: 100\n",
      "\n",
      "Best random state: 20\n",
      "Test set 1: 0.50\n",
      "Test set 2: 0.52\n",
      "Test set 3: 0.54\n"
     ]
    }
   ],
   "source": [
    "best_i = []\n",
    "for i in [100,500,1000]:\n",
    "    print('Max iter: ' + str(i) + '\\n')\n",
    "    for j in [1,7,10,20]:\n",
    "        print('Random state: ' + str(j) + '\\n')\n",
    "        # Target 1 day\n",
    "        ann = MLPClassifier(random_state=j, max_iter=i)\n",
    "        ann.fit(X_train_1, Y_train_1)\n",
    "        train_acc_1 = accuracy_score(y_true= Y_train_1, y_pred= ann.predict(X_train_1))\n",
    "        scores_1 = cross_val_score(ann, X_train_1_80, Y_train_1_80, \n",
    "                                 cv=5, scoring='accuracy', \n",
    "                                 verbose = 0)\n",
    "        print(\"Train set 1: {:.2f}\".format(train_acc_1))\n",
    "        print('Validation set 1: {:.2f}'.format(scores_1.mean()))\n",
    "        print('\\n')\n",
    "        # Target 5 days\n",
    "        ann = MLPClassifier(random_state=j, max_iter=i)\n",
    "        ann.fit(X_train_2, Y_train_2)\n",
    "        train_acc_2 = accuracy_score(y_true= Y_train_2, y_pred= ann.predict(X_train_2))\n",
    "        scores_2 = cross_val_score(ann, X_train_2_80, Y_train_2_80, \n",
    "                                 cv=5, scoring='accuracy', \n",
    "                                 verbose = 0)\n",
    "        print(\"Train set 2: {:.2f}\".format(train_acc_2))\n",
    "        print('Validation set 2: {:.2f}'.format(scores_2.mean()))\n",
    "        print('\\n')\n",
    "        # Target 30 days\n",
    "        ann = MLPClassifier(random_state=j, max_iter=i)\n",
    "        ann.fit(X_train_3, Y_train_3)\n",
    "        train_acc_3 = accuracy_score(y_true= Y_train_3, y_pred= ann.predict(X_train_3))\n",
    "        scores_3 = cross_val_score(ann, X_train_3_80, Y_train_3_80, \n",
    "                                 cv=5, scoring='accuracy', \n",
    "                                 verbose = 0)\n",
    "        print(\"Train set 3: {:.2f}\".format(train_acc_3))\n",
    "        print('Validation set 3: {:.2f}'.format(scores_3.mean()))\n",
    "        print('\\n')\n",
    "        best_i.append([i, j, scores_1.mean() + scores_2.mean() + scores_3.mean()])\n",
    "        \n",
    "i = max(best_i, key=lambda x:x[2])[0]\n",
    "j = max(best_i, key=lambda x:x[2])[1]\n",
    "print('Best max iter: ' + str(i))\n",
    "print('Best random state: ' + str(j))\n",
    "\n",
    "# Target 1 day\n",
    "ann = MLPClassifier(random_state=j, max_iter=i)\n",
    "ann.fit(X_train_1_80, Y_train_1_80)\n",
    "test_acc_1 = accuracy_score(y_true= Y_test_1, y_pred= ann.predict(X_test_1))\n",
    "print('Test set 1: {:.2f}'.format(test_acc_1))\n",
    "\n",
    "# Target 5 days\n",
    "ann = MLPClassifier(random_state=j, max_iter=i)\n",
    "ann.fit(X_train_2_80, Y_train_2_80)\n",
    "test_acc_2 = accuracy_score(y_true= Y_test_2, y_pred= ann.predict(X_test_2))\n",
    "print('Test set 2: {:.2f}'.format(test_acc_2))\n",
    "\n",
    "# Target 30 days\n",
    "ann = MLPClassifier(random_state=j, max_iter=i)\n",
    "ann.fit(X_train_3_80, Y_train_3_80)\n",
    "test_acc_3 = accuracy_score(y_true= Y_test_3, y_pred= ann.predict(X_test_3))\n",
    "print('Test set 3: {:.2f}'.format(test_acc_3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T16:34:28.709285Z",
     "start_time": "2023-11-23T16:25:30.268276Z"
    }
   },
   "id": "70f38e1723ec5e6d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a7b86753ed2ec1fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
