{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: da rifare per ogni stock\n",
    "sheet_names = [\n",
    "    'Info',\n",
    "    'Historical',\n",
    "    'Income Statement',\n",
    "    'Quarterly Income Statement',\n",
    "    'Cashflow',\n",
    "    'Institutional Holders',\n",
    "    'Mutual Fund Holders',\n",
    "    'Major Holders'\n",
    "]\n",
    "\n",
    "#riempire stocks di tutti i vari codici, fare la retrive di tutti i file e buttarli in df_stock per poi poter lavorare su tutti i dati\n",
    "directory = \"./data\"\n",
    "stocks = [os.path.join(directory, file) for file in os.listdir(directory)]\n",
    "stocks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Integrazione dei dati finanziarii\n",
    "Colonne aggiunte:\n",
    "- **Daily_Return**: rendimento giornaliero.\n",
    "- **Target_1day**: indica se il prezzo di chiusura del giorno successivo sarà superiore (1) o inferiore (0) rispetto al prezzo di chiusura del giorno corrente.\n",
    "- **Target_5days**: indica se il prezzo di chiusura a 5 giorni nel futuro sarà superiore (1) o inferiore (0) rispetto al prezzo di chiusura del giorno corrente.\n",
    "- **Target_30days**: indica se il prezzo di chiusura a 30 giorni nel futuro sarà superiore (1) o inferiore (0) rispetto al prezzo di chiusura del giorno corrente.\n",
    "\n",
    "Integrato i vari sheet \"Income Statement\", \"Quarterly Income Statement\" e \"Cashflow\" in un singolo excel. NB: Dato che questi fogli contengono dati finanziari annuali o trimestrali un approccio comune è portare avanti l'ultimo valore noto per ogni giorno fino a quando non si dispone di un nuovo valore. Per alcunii anni finanziari sarà Nan perché non li abbiamo.\n",
    "\n",
    "Lista delle azioni alle quali mancano pezzi:\n",
    "- **1398.HK** manca income_statement.normalized_EBITA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2000-01-05    005380KS\n",
      "2000-01-06    005380KS\n",
      "2000-01-07    005380KS\n",
      "2000-01-10    005380KS\n",
      "2000-01-11    005380KS\n",
      "                ...   \n",
      "2023-10-06    005380KS\n",
      "2023-10-10    005380KS\n",
      "2023-10-11    005380KS\n",
      "2023-10-12    005380KS\n",
      "2023-10-13    005380KS\n",
      "Name: Ticker, Length: 5954, dtype: object\n",
      "counter 0, len 5954\n",
      "005380KS\n",
      "Date\n",
      "2000-01-05    005930KS\n",
      "2000-01-06    005930KS\n",
      "2000-01-07    005930KS\n",
      "2000-01-10    005930KS\n",
      "2000-01-11    005930KS\n",
      "                ...   \n",
      "2023-10-06    005930KS\n",
      "2023-10-10    005930KS\n",
      "2023-10-11    005930KS\n",
      "2023-10-12    005930KS\n",
      "2023-10-13    005930KS\n",
      "Name: Ticker, Length: 5963, dtype: object\n",
      "counter 5954, len 5963\n",
      "005930KS\n",
      "Date\n",
      "2004-06-17    0700HK\n",
      "2004-06-18    0700HK\n",
      "2004-06-21    0700HK\n",
      "2004-06-22    0700HK\n",
      "2004-06-23    0700HK\n",
      "               ...  \n",
      "2023-10-09    0700HK\n",
      "2023-10-10    0700HK\n",
      "2023-10-11    0700HK\n",
      "2023-10-12    0700HK\n",
      "2023-10-13    0700HK\n",
      "Name: Ticker, Length: 4775, dtype: object\n",
      "counter 5963, len 4775\n",
      "0700HK\n",
      "Date\n",
      "2006-10-31    1398HK\n",
      "2006-11-01    1398HK\n",
      "2006-11-02    1398HK\n",
      "2006-11-03    1398HK\n",
      "2006-11-06    1398HK\n",
      "               ...  \n",
      "2023-10-09    1398HK\n",
      "2023-10-10    1398HK\n",
      "2023-10-11    1398HK\n",
      "2023-10-12    1398HK\n",
      "2023-10-13    1398HK\n",
      "Name: Ticker, Length: 4166, dtype: object\n",
      "counter 4775, len 4166\n",
      "1398HK\n",
      "Date\n",
      "2000-01-05    9984T\n",
      "2000-01-06    9984T\n",
      "2000-01-07    9984T\n",
      "2000-01-10    9984T\n",
      "2000-01-11    9984T\n",
      "              ...  \n",
      "2023-10-06    9984T\n",
      "2023-10-10    9984T\n",
      "2023-10-11    9984T\n",
      "2023-10-12    9984T\n",
      "2023-10-13    9984T\n",
      "Name: Ticker, Length: 5949, dtype: object\n",
      "counter 4166, len 5949\n",
      "9984T\n",
      "Date\n",
      "1980-12-15    AAPL\n",
      "1980-12-16    AAPL\n",
      "1980-12-17    AAPL\n",
      "1980-12-18    AAPL\n",
      "1980-12-19    AAPL\n",
      "              ... \n",
      "2023-10-09    AAPL\n",
      "2023-10-10    AAPL\n",
      "2023-10-11    AAPL\n",
      "2023-10-12    AAPL\n",
      "2023-10-13    AAPL\n",
      "Name: Ticker, Length: 10799, dtype: object\n",
      "counter 5949, len 10799\n",
      "AAPL\n",
      "Date\n",
      "2001-09-04    AIRPA\n",
      "2001-09-05    AIRPA\n",
      "2001-09-06    AIRPA\n",
      "2001-09-07    AIRPA\n",
      "2001-09-10    AIRPA\n",
      "              ...  \n",
      "2023-10-09    AIRPA\n",
      "2023-10-10    AIRPA\n",
      "2023-10-11    AIRPA\n",
      "2023-10-12    AIRPA\n",
      "2023-10-13    AIRPA\n",
      "Name: Ticker, Length: 5678, dtype: object\n",
      "counter 10799, len 5678\n",
      "AIRPA\n",
      "Date\n",
      "1997-05-16    AMZN\n",
      "1997-05-19    AMZN\n",
      "1997-05-20    AMZN\n",
      "1997-05-21    AMZN\n",
      "1997-05-22    AMZN\n",
      "              ... \n",
      "2023-10-09    AMZN\n",
      "2023-10-10    AMZN\n",
      "2023-10-11    AMZN\n",
      "2023-10-12    AMZN\n",
      "2023-10-13    AMZN\n",
      "Name: Ticker, Length: 6647, dtype: object\n",
      "counter 5678, len 6647\n",
      "AMZN\n",
      "Date\n",
      "1962-01-03    BA\n",
      "1962-01-04    BA\n",
      "1962-01-05    BA\n",
      "1962-01-08    BA\n",
      "1962-01-09    BA\n",
      "              ..\n",
      "2023-10-09    BA\n",
      "2023-10-10    BA\n",
      "2023-10-11    BA\n",
      "2023-10-12    BA\n",
      "2023-10-13    BA\n",
      "Name: Ticker, Length: 15552, dtype: object\n",
      "counter 6647, len 15552\n",
      "BA\n",
      "Date\n",
      "2018-07-26    BE\n",
      "2018-07-27    BE\n",
      "2018-07-30    BE\n",
      "2018-07-31    BE\n",
      "2018-08-01    BE\n",
      "              ..\n",
      "2023-10-09    BE\n",
      "2023-10-10    BE\n",
      "2023-10-11    BE\n",
      "2023-10-12    BE\n",
      "2023-10-13    BE\n",
      "Name: Ticker, Length: 1314, dtype: object\n",
      "counter 15552, len 1314\n",
      "BE\n",
      "Date\n",
      "1962-01-03    CVX\n",
      "1962-01-04    CVX\n",
      "1962-01-05    CVX\n",
      "1962-01-08    CVX\n",
      "1962-01-09    CVX\n",
      "             ... \n",
      "2023-10-09    CVX\n",
      "2023-10-10    CVX\n",
      "2023-10-11    CVX\n",
      "2023-10-12    CVX\n",
      "2023-10-13    CVX\n",
      "Name: Ticker, Length: 15552, dtype: object\n",
      "counter 1314, len 15552\n",
      "CVX\n"
     ]
    }
   ],
   "source": [
    "# TODO: da fare per ogni stock\n",
    "counter = 0\n",
    "for file in stocks:\n",
    "    if file.split(\"/\")[1].split(\"\\\\\")[1].replace(\".\", \"\")[:-4] != \"1398.HK\":\n",
    "        df_stock = pd.ExcelFile(file)\n",
    "        \n",
    "        # prevent false postive warnings, reference_ https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas\n",
    "        pd.options.mode.chained_assignment = None # default='warn'\n",
    "        \n",
    "        # Loading the 'Historical' data stock\n",
    "        historical_data = df_stock.parse('Historical')\n",
    "        \n",
    "        # Renaming and setting the Date column\n",
    "        historical_data.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)\n",
    "        historical_data['Date'] = pd.to_datetime(historical_data['Date'])\n",
    "        historical_data.set_index('Date', inplace=True)\n",
    "        # Calculate daily return\n",
    "        historical_data['Daily_Return'] = historical_data['Close'].pct_change()\n",
    "        \n",
    "        # Create target variables for next day, next 5 days and next 30 days\n",
    "        historical_data['Target_1day'] = (historical_data['Close'].shift(-1) > historical_data['Close']).astype(int)\n",
    "        historical_data['Target_5days'] = (historical_data['Close'].shift(-5) > historical_data['Close']).astype(int)\n",
    "        historical_data['Target_30days'] = (historical_data['Close'].shift(-30) > historical_data['Close']).astype(int)\n",
    "        \n",
    "        # Drop rows with NaN values (will be present due to the shifting for target creation)\n",
    "        historical_data = historical_data.dropna()\n",
    "        \n",
    "        # Loading the 'Income Statement' data for XOM\n",
    "        income_statement = df_stock.parse('Income Statement')\n",
    "        \n",
    "        # Transposing the data for easier integration\n",
    "        income_statement = income_statement.set_index('Unnamed: 0').transpose()\n",
    "        income_statement.index = pd.to_datetime(income_statement.index)\n",
    "        \n",
    "        \n",
    "        # Selecting some of the key financial metrics (you can add or remove based on relevance)\n",
    "        selected_metrics = [\n",
    "            'Normalized EBITDA',\n",
    "            'Total Unusual Items',\n",
    "            'Total Unusual Items Excluding Goodwill'\n",
    "        ]\n",
    "        \n",
    "        # check if columns exist, in case create them\n",
    "        for metric in selected_metrics:\n",
    "            if metric not in income_statement.columns:\n",
    "                income_statement[metric] = np.nan\n",
    "                \n",
    "        \n",
    "        income_statement = income_statement[selected_metrics]\n",
    "        \n",
    "        # Merging the income statement data with the historical data\n",
    "        merged_data = historical_data.join(income_statement, how='left')\n",
    "        \n",
    "        # Forward filling the NaN values\n",
    "        merged_data[selected_metrics] = merged_data[selected_metrics].fillna(method='ffill')\n",
    "        \n",
    "        # Loading the 'Cashflow' data for XOM\n",
    "        cashflow = df_stock.parse('Cashflow')\n",
    "        \n",
    "        # Transposing the data for easier integration\n",
    "        cashflow = cashflow.set_index('Unnamed: 0').transpose()\n",
    "        cashflow.index = pd.to_datetime(cashflow.index)\n",
    "        \n",
    "        # Selecting some of the key cashflow metrics (you can add or remove based on relevance)\n",
    "        selected_cashflow_metrics = [\n",
    "            'Operating Cash Flow',\n",
    "            'Capital Expenditure',\n",
    "            'Free Cash Flow'\n",
    "        ]\n",
    "        \n",
    "        for metric in selected_cashflow_metrics:\n",
    "            if metric not in cashflow.columns:\n",
    "                cashflow[metric] = np.nan\n",
    "        \n",
    "        cashflow = cashflow[selected_cashflow_metrics]\n",
    "        \n",
    "        # Merging the cashflow data with the existing dataframe\n",
    "        merged_data = merged_data.join(cashflow, how='left', rsuffix='_cashflow')\n",
    "        \n",
    "        # Forward filling the NaN values\n",
    "        merged_data[selected_cashflow_metrics] = merged_data[selected_cashflow_metrics].fillna(method='ffill')\n",
    "        \n",
    "        if 'Ticker' not in merged_data.columns:\n",
    "            merged_data['Ticker'] = file.split(\"/\")[1].split(\"\\\\\")[1].replace(\".\", \"\")[:-4]\n",
    "        \n",
    "        # Display the updated dataframe with integrated cashflow metrics\n",
    "        merged_data.iloc[counter : counter + len(merged_data), merged_data.columns.get_loc(\"Ticker\")] = file.split(\"/\")[1].split(\"\\\\\")[1].replace(\".\", \"\")[:-4]\n",
    "        print(merged_data.Ticker)\n",
    "        print(f\"counter {counter}, len {len(merged_data)}\")\n",
    "        \n",
    "        counter = len(merged_data)\n",
    "        print(file.split(\"/\")[1].split(\"\\\\\")[1].replace(\".\", \"\")[:-4])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-19T20:34:12.863464100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: spiegare perchè togliamo i quarterly\n",
    "#merged_data.drop(columns=['Normalized EBITDA_quarterly', 'Total Unusual Items_quarterly', 'Total Unusual Items Excluding Goodwill_quarterly'], inplace=True)\n",
    "merged_data.iloc[1 : counter + len(merged_data), merged_data.columns.get_loc(\"Ticker\")] = file.split(\"/\")[1].split(\"\\\\\")[1].replace(\".\", \"\")[:-4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering\n",
    "- **Medie mobili**: Calcoliamo le medie mobili a breve e lungo termine per il prezzo di chiusura, che sono comuni nel trading algoritmico. Ad esempio, medie mobili a 5, 10, 30 e 50 giorni.\n",
    "- **RSI (Relative Strength Index)**: Questo è un indicatore di momentum che può aiutare a identificare se un'azione è in condizione di \"overbought\" o \"oversold\".\n",
    "- **MACD (Moving Average Convergence Divergence)**: Un altro indicatore di momentum.\n",
    "- **Bollinger Bands**: Questi sono basati su medie mobili e possono aiutare a identificare se un prezzo è relativamente alto o basso.\n",
    "- **Volatilità**: Potremmo calcolare la volatilità come la deviazione standard dei rendimenti giornalieri in una finestra temporale specifica."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: da fare per ogni stock\n",
    "# TODO: controllare gpt\n",
    "\n",
    "# Moving Averages\n",
    "merged_data['MA_5'] = merged_data['Close'].rolling(window=5).mean()\n",
    "merged_data['MA_10'] = merged_data['Close'].rolling(window=10).mean()\n",
    "merged_data['MA_30'] = merged_data['Close'].rolling(window=30).mean()\n",
    "merged_data['MA_50'] = merged_data['Close'].rolling(window=50).mean()\n",
    "\n",
    "# RSI\n",
    "delta = merged_data['Close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "avg_gain = gain.rolling(window=14).mean()\n",
    "avg_loss = loss.rolling(window=14).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "merged_data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# MACD\n",
    "merged_data['MACD'] = merged_data['Close'].ewm(span=12, adjust=False).mean() - merged_data['Close'].ewm(span=26, adjust=False).mean()\n",
    "merged_data['Signal_Line'] = merged_data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# Bollinger Bands\n",
    "merged_data['Bollinger_Mid_Band'] = merged_data['Close'].rolling(window=20).mean()\n",
    "merged_data['Bollinger_Upper_Band']  = merged_data['Bollinger_Mid_Band'] + 1.96*merged_data['Close'].rolling(window=20).std()\n",
    "merged_data['Bollinger_Lower_Band']  = merged_data['Bollinger_Mid_Band'] - 1.96*merged_data['Close'].rolling(window=20).std()\n",
    "\n",
    "# Volatility\n",
    "merged_data['Volatility'] = merged_data['Daily_Return'].rolling(window=5).std()\n",
    "\n",
    "to_drop_na = ['MA_5', 'MA_10', 'MA_30', 'MA_50', 'RSI', 'Volatility']\n",
    "\n",
    "for column in to_drop_na:\n",
    "    merged_data[column] = merged_data[column].fillna(0)\n",
    "\n",
    "# Display the dataset with new features\n",
    "merged_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: spiegare perche tagliamo il numero di record\n",
    "merged_data = merged_data[merged_data.index >= '2020-06-30']\n",
    "merged_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# da fare per ogni stock\n",
    "output_filepath = \"processed_nomedellostock.xlsx\"\n",
    "len(merged_data)\n",
    "merged_data.to_excel(output_filepath)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T15:35:59.083807100Z",
     "start_time": "2023-10-19T15:35:58.506357800Z"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
