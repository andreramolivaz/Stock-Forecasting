
TEORIA
# Formula matematica modello -> \[Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i\] Con $\varepsilon_i$ variabili casuali independenti ed identicamente distribuite a media 0 con una varianza costante $\sigma^1$ || alcoholi = α + β locationi + εi conεi iidεi ∼N(0,σ2)  # Assunzioni modello -> Le assunzioni si possono scrivere in maniera sintetica come $Y_i|X=x_i \stackrel{iid}{\sim} N(\beta_0 + \beta_1 x_i, \sigma)$ per ogni $i= 1, \ldots, n$. Si deve quindi verificare che la relazione tra X e Y sia lineare e che le osservazioni seguano una normale e abbiano varianza costante. Inoltre si presume una certa indipendenza tra gli errori ma difficile da verificare. Le assunzioni del modello lineare semplice sono: * linearità della relazione tra X e Y* Indipendenza delle osservazioni * Normalità degli errori * Eguaglianza delle varianza: omoschedasticità Queste assunzioni vengono tipicamente verificate tramite lo studio dei residui. Dalle informazioni a nostra disposizione non c'è modo di sapere se le aziende in esame sono indipendenti tra loro. Dai grafici dei residui si nota che le altre assunzioni sembrano non essere valide per il modello `fit1`: i residui dimostrano di non essere sparsi in maniera casuale in funzione dei valori stimati, indicando problemi con l'assunzione di linearità della relazione (che già si notava nel grafico fatto al punto b), la varianza cresce al crescere dei valori stimati, le code della distribuzione dei residui sono più pesanti di quelle che ci si aspetterebbe da un campione estratto da una normale. Inoltre ci sono alcuni punti che hanno una forte influenza sulla stima, come evidenziato dal fatto che per alcuni punti la distanza di Cook e molto grande. # Centrare X nella media -> la relazione descritta è la stessa(r squared significatività e coeff) L'intercetta ora descrive il valore medio del peso di un uomo di statura media.  Il valore del coefficiente angolare non cambia: questo perché non cambiano la covarianza tra i due campioni e la somma dei scarti quadrati di $x$ (per le proprietà di varianza e covarianza). Questo implica che non cambia la differenza di peso tra due uomini la cui altezza differisce per un pollice.  # Scalare modello sia su X che su Y ->  Il valore stimato per il coefficiente angolare ora indica il cambiamento atteso in standard deviations di Peso per un cambiamento di 1 standard deviation dell'Altezza. Questo tipo di trasformazione può essere particolarmente utile quando si stimano modelli multivariati e nella situazione in cui si stiano usando variabili con valori numerici molto alti o molto piccoli (e/o scale di misura che possono coprire valori molto diversi): in questo modo si possono evitare problemi di tipo numerico. X = (X - mean(X))/sd(X) # Due modelli trainati su subset diversi (uno contenuto nell'altro) -> Quello che cambia è la stima della variabilità delle stime, che aumenta. Da questo segue che il p-value per il test della significatività dei parametri sia leggermente più alto. Questo è legato al fatto che la variabilità delle stime è legata alla numerosità campionaria: con un campione con meno osservazioni si ottengono stime più variabili. set.seed(178); sampledObs <- sample(seq(1, 250), size = 50) ... data = bodyfat[sampledObs,]

# Verificare se salari medi sono uguali per M/F -> statistica test t.test(salary~sex, data = salaries) oppure summary(lm(salary~sex, data = salaries))

# Assunzioni: Per poter ottenere stime puntuali di α e β assumiamo che i dati (y1, . . . , yn) siano indipendenti tra loro, identicamente distribuiti con varianza costante e valore atteso che cambia approssimativamente linearmente con X. Per poter costruire delle stime intervallare dobbiamo anche assumere che i dati siano distribuiti secondo una normale# qq-plot verifica normalità -> I punti infatti si allineano sulla bisettrice, indicando che i valori empirici dei quantili del campione corrispondo ai valori che ci si potrebbe aspettare teoricamente estraendo un campione di dimensione n dalla disitrbuzione di riferimento. Il grafico sulla destra invece mostra che il campione ha delle code più pesanti della disitrbuzione di riferimento.
# Statistica F -> La statistica test per il test della signi􏰁cativitá globale è piuttosto grande, ad indicare che, per qualunque livello di signi􏰁cativitá usato comunemente, si può rigettare l'ipotesi nulla che tutti i coe􏰃cienti di regressione siano pari a 0: il modello cattura una porzione rilevante della variabilitá dei dati.

# Confronto due ci per predittore -> L'intervallo di confdenza al 99% per il parametro contiene 0, mentre l'intervallo di confdenza al 90% non contiene 0: ne deduciamo che il p-value per la veri􏰁ca di ipotesi H0 : βage = 0 V S H1 : βage ̸= 0 è più grande di 0.01 ma più piccolo di 0.1 (il valore è infatti 0.08 circa).


# GLM Si proceda a fare un test per testare se il valore del coefficiente relativo al predittore age `e uguale a 0.1. Si usi un livello di significativit`a del 90%. E Si delinei brevemente la base teorica usata per derivare il test svolto nel punto precedente, commentando la validit`a di tale base per l’applicazione al punto. -> confint.default(f0, parm = "age", level = 0.9) # 0.1 not in interval, reject H0 where b1 = 0.1 La stima per i parametri dei modelli GLM è derivata tramite la massimizzazione della verosimiglianza, quindi le stime derivate godono delle proprietà (asintotiche) degli stimatori di massima verosimiglianza: gli stimatori sono non distorti, hanno varianza nota derivata dalla matrice di informazione di Fisher e si distribuiscono approssimativamente secondo una normale. Il test derivato al punto 4 si basa su queste proprietà, ma la dimensionalità campionaria alla base delle stime non è particolarmente grande e si dovrebbe quindi essere cauti nell'applicazione di metodi basati sulle proprietà asintotiche degli stimatori di massima verosimiglianza.

# GLM Si fornisca una stima puntuale e una stima intervallare di questa probabilit`a usando un livello di confidenza del 96%. Si commenti l’ampiezza degli intervalli identificati. predict(tumor_selAIC, newdata = nd, type = "response")
preds <- predict(tumor_selAIC, newdata = nd, type = "link", se.fit = TRUE)
pint <- cbind(tumor_selAIC$family$linkinv(preds$fit + qnorm(.02) * preds$se.fit),
tumor_selAIC$family$linkinv(preds$fit + qnorm(.98) * preds$se.fit))

PLOT
# Visualizzazione con confidenza# Si usi il modello stimato al punto precedente (2.a) per derivare un intervallo di confidenza al 98% # per la probabilità che due aziende con un valore di `Assets` pari a 2000 e 20000 siano banche. # Si produca inoltre una visualizzazione che mostri come varia la stima della probabilità che # un'azienda sia una banca in funzione di `Assets` con un intervallo di confidenza al 98%. nd <- data.frame(Assets = c(2000,20000))preds <- predict(fit1, newdata = nd, type = "link", se.fit = TRUE)# LOWER BOUNDS cbind(binomial()$linkinv(preds$fit + qnorm(0.01) * preds$se.fit),      # UPPER BOUNDS       binomial()$linkinv(preds$fit + qnorm(0.99) * preds$se.fit))nd <- data.frame(Assets = seq(0,60000))preds <- predict(fit1, newdata = nd, type = "link", se.fit = TRUE)plot(dex1$Assets, jitter(as.numeric(dex1$Banks == "Bank"),amount = 0.05),      ylab = "P(Azienda = Bank)" ,pch = 16)lines(nd$Assets, binomial()$linkinv(preds$fit), col = 2)lines(nd$Assets, binomial()$linkinv(preds$fit + qnorm(0.01) * preds$se.fit), col = 2, lty = 2)lines(nd$Assets, binomial()$linkinv(preds$fit + qnorm(0.99) * preds$se.fit), col = 2, lty = 2)# plot che mostra la relazione stimata dal modello `fit1` con ci  e pi per il valore atteso di `MarketValue` plot(MarketValue ~ CashFlow, data = dex1)abline(fit1, col = 2)ci <- predict(fit1, interval = "conf")lines(dex1$CashFlow, ci[,2], col = "lightblue")lines(dex1$CashFlow, ci[,3], col = "lightblue")pi <- predict(fit1, interval = "pred")lines(dex1$CashFlow, pi[,2], col = "green")lines(dex1$CashFlow, pi[,3], col = "green")
# Plot with subset# Subset the data for male and female householdsmale_data <- subset(dex1, Sesso == "M")female_data <- subset(dex1, Sesso == "F")# Create the linear regression models for male and female householdsfit_male <- lm(Consumi ~ Reddito, data = male_data)fit_female <- lm(Consumi ~ Reddito, data = female_data)# Plot for male householdsplot(male_data$Reddito, male_data$Consumi, main = "Income vs Consumption (Male)", xlab = "Income", ylab = "Consumption")abline(fit_male, col = "blue", lwd = 2)# Plot for female householdsplot(female_data$Reddito, female_data$Consumi, main = "Income vs Consumption (Female)", xlab = "Income", ylab = "Consumption")abline(fit_female, col = "red", lwd = 2)# legend("topright", legend = c("Male", "Female"), col = c("blue", "red"), pch = 1)

# GLM Plot per binomiale
# Si esegua una prima stima in cui la variabile Class, cio`e la variabile che indica la 
# classificazione del tumore, dipende dalla variabile Thick: si produca un grafico che mostra come la # probabilit`a che un tumore sia benigno dipende da Thick. Si crei inoltre un intervallo di #confidenza al 96% per il parametro relativo alla variabile Thick.
tumor_thick <- glm(Class~Thick, data = wbca, family=binomial)
plot(jitter(Class, amount = 0.15)~Thick, data = wbca, ylab = "P(tumor is benign)") lines(sort(wbca$Thick), fitted(tumor_thick)[order(wbca$Thick)],col=2) 
confint.default(tumor_thick, parm = "Thick", level = .96)


# plot relazione due variabili di un ml bisogna "fissare” il valore dell’altra variabile. Questo si può fare usando la funzione predict (o approcci simili). Possiamo quindi mostrare la retta che mostri la relazione tra wt e mpg tendendo fisso il valore di year : plot(mpg~wt, data= autompg)
nd <- data.frame(wt = seq(1500, 5200, length.out = 100), year = mean(autompg$year))
lines(nd$wt, predict(fit, nd), lwd=2,col=4)

COMANDI Rcoef(fit) ## valori stimati dei coefficienti del modello confint(fit) ## intervalli di confidenza per i coefficienti del modello ## per aggiungere trasformazioni di X come predittori si usa la funzione I(.)## fit <- lm(y~x1+x2+I(x2^2), data = df) ## per polinomi ## fit <- lm(y~x1+poly(x2,2), data = df)## fit <- lm(y~x1+poly(x2,2, raw=TRUE), data = df)## la matrice di disegno usata nella stimamodel.matrix(fit)## predizione # per i valori osservati delle Xfitted(fit)predict(fit) ## predict produce anche intervalli di confidenza e predizionepredict(fit, interval = "confidence") predict(fit, interval = "prediction") ## per un nuovo set di punti nd <- data.frame(x1 = c(0.2,0.8), x2 = c(0.3,0.6))predict(fit, newdata = nd)# residui residuals(fit) ## these are y - fitted(fit)rstandard(fit) ## standardised residuals rstudent(fit)  ## studentized residuals # goodness of fit/ bontà di adattamento plot(fit) # grafici riassuntiviIC = -2*logLik(M) +  k * p(M)AIC(fit, k = 2); BIC(fit); logLik(fit) ## verosimiglianza e criteri di informazionehatvalues(fit) ##  leverages - punti di leva car::vif(fit) ## variance inflation factors - ci sono problemi di colinearità? cooks.distance(fit) # outliers/punti particolari ## test anova per modelli annidati # anova(small_model, big_model)anova(lm(y~x1, data = df), fit)## model selection ## la funzione step qui usata per un algoritmo forward come esempio ## opzioni importanti # scope per delineare l'ambito della ricerca# k: per definire la penalizzazione del criterio di informazione# direction: per la direzione: forward, backward, bothstep(object = lm(y~1, data = df),      scope = list(lower = lm(y~1, data = df),                   upper = fit),      direction = "forward",     k = 2) ## # Model Selection# FS - AICnull <- lm(inter ~ 1, data = dex1)full <- lm(inter ~ ., data = dex1)step(object = null,      scope=list(lower=null, upper=full),      direction="forward", k=2, trace=1)# FS - BICstep(object = null, scope=list(lower=null, upper=full),      direction="forward", k=log(nrow(dex1)), trace=1)# BS - AICstep(object = full, scope=list(lower=null, upper=full),      direction="backward", k=2, trace=1)# BS - BICstep(object = full, scope=list(lower=null, upper=full),      direction="backward", k=log(nrow(dex1)), trace=1)# Step - AICstep(object = intermediate,      scope = list(lower = null, upper=full),     direction="both", trace=1, k=2)# Step - BICstep(object = intermediate,      scope = list(lower = null, upper=full),     direction="both", trace=1, k=log(nrow(dex1)))## trasformazione di Box-Cox ## da usare se y|X risulta non-normale ## MASS::boxcox# Hypothesis testing - TS = EST-HYP/SE ~ t_(alpha/2,n-p)# 1. Compute TSTS <- (beta_j - hyp)/se_beta_j# 2. Check p-value2*pt(abs(TS), df=nrow(df)-p, lower.tail = FALSE)## GLM - modelli lineari generalizzati -------##in questo esempio usiamo una Poisson df <- data.frame(x1 = runif(15), x2 = runif(15), y  = rpois(15, 6))## stima del modello fit <- glm(y~x1+x2, data = df, family = poisson()) ## di default si usa la funzione legame canonicapoisson()$linksummary(fit) ## varie informazioni riassuntive sulla stimacoef(fit) ## valori stimati dei coefficienti del modello confint.default(fit) ## intervalli di confidenza per i coefficienti del modello ## predizione # per i valori osservati delle Xfitted(fit) ## predizione sulla scale di Y (exp(linear.predictor))predict(fit) ## predict di default mostra il predittore linearepredict(fit, type = "response") ## predict accetta un'opzione type per mostrare i valori stimati sulla scala delle Y ## per un oggetto glm predict non può costruire intervalli di confidenza (e non si possono costruire intervalli di predizione)predict(fit, se.fit = TRUE) # con opzione se.fit si ottiene lo standard error per il predittore lineare ## per un nuovo set di punti nd <- data.frame(x1 = c(0.2,0.8), x2 = c(0.3,0.6))a <- predict(fit, newdata = nd, se.fit = TRUE); a# intervalli di confidenza manualialpha = 0.05cbind(a$fit + qnorm(alpha/2) * a$se.fit,       a$fit + qnorm(1-alpha/2) * a$se.fit)              # residui residuals(fit) ## di default deviance residuals residuals(fit, type = "pearson") ## type = c("deviance", "pearson", "response"))# goodness of fit/ bontà di adattamento plot(fit) # grafici riassuntiviAIC(fit, k = 2); BIC(fit); logLik(fit) ## verosimiglianza e criteri di informazione## test anova per modelli annidati # anova(small_model, big_model)anova(glm(y~x1, data = df, family=poisson()), fit, test = "LRT")# GLM con ND e confint al 98%nd <- data.frame(Assets = c(2000, 20000))pred <- predict(fit1, newdata = nd, type = "link", se.fit = T)cbind(fit1$family$linkinv(pred$fit + qnorm(0.01) * pred$se.fit),      fit1$family$linkinv(pred$fit + qnorm(0.99) * pred$se.fit))## glm as a classifier ------------- ## funzioni implementate nelle slides/laboratorio cv_class <- function(K=5, dat, model, cutoff = 0.5){  assign_group <- rep(seq(1,K), each = floor(nrow(dat)/K))  ### this ensures we use all points in the dataset  ### this way we might have subgroups of different size   if(length(assign_group) != nrow(dat)) assign_group <- c(assign_group, sample(seq(1,K)))[1:nrow(dat)]   assign_group <- sample(assign_group, size = nrow(dat))  error <- 0  for(j in 1:K){    whichobs <- (assign_group == j)    ## fit a model WITHOUT the hold-out data    folded_model <- suppressWarnings(glm(model$formula,                                          data = dat[!whichobs,],                                          family = "binomial"))    ## evaluate the model on the hold-out data    fitted <- suppressWarnings(predict(folded_model,                                       dat[whichobs,],                                        type="response"))    observed <- dat[whichobs, strsplit(paste(model$formula), "~")[[2]]]    error <- error + mean(observed != (fitted>cutoff))/K     ### in cv.glm the actual error is calculated as (y - p(y=1))     # error <- error + mean((observed - fitted)^2)/K     ### the mis-classification rate will depend on how we decide what is assigned to each category   }  error}make_conf_mat <- function(predicted, actual) {  table(predicted = predicted, actual = actual)}get_sens <- function(conf_mat) {  conf_mat[2, 2] / sum(conf_mat[, 2])}# Note that this function is good for illustrative purposes, but is easily broken. (Think about what happens if there are no "positives" predicted.)get_spec <-  function(conf_mat) {  conf_mat[1, 1] / sum(conf_mat[, 1])}# --------------- Classifier ------------------# GLM Classifier - Logistic Regression# 1. Train-Test Splitset.seed(42)spam_idx <- sample(nrow(spam), 2000)spam_trn <- spam[spam_idx,] spam_tst <- spam[-spam_idx,]## 2. success and cutoff ifelse(p > cutoff, 1, 0)## 3. Define measure of error## loocv-fold cv on misclassification rateloocv_glm <- function(n, fit, target,  dataset){  # n observations = k   n <- nrow(dataset)  # save the errors of classification  errorClass <- rep(NA, n)  # For each i-th observation (row) in the dataset  for(i in 1:n){    # Fit the model without it    # Check formula and family    fit <- glm(target ~ .,                family = binomial,                data = dataset,                subset = -i)    # Compute the misclassfication rate    # With the new model which excludes the i_th observation    # On the i_th observation, to see how far we are.    errorClass[i] <- (dataset$target[i] -                         ifelse(predict(fit,                                        newdata = dataset[i,],                                        type ="r") < 0.5, 0, 1))  }}## k-fold cross validation on misclassification ratecv_class <- function(K=5, dat, model, cutoff = 0.5){  assign_group <- rep(seq(1,K), each = floor(nrow(dat)/K))  ### this ensures we use all points in the dataset  ### this way we might have subgroups of different size   if(length(assign_group) != nrow(dat)) assign_group <- c(assign_group, sample(seq(1,K)))[1:nrow(dat)]   assign_group <- sample(assign_group, size = nrow(dat))  error <- 0  for(j in 1:K){    whichobs <- (assign_group == j)    ## fit a model WITHOUT the hold-out data    folded_model <- suppressWarnings(glm(model$formula, data = dat[!whichobs,], family = "binomial"))    ## evaluate the model on the hold-out data    fitted <- suppressWarnings(predict(folded_model,dat[whichobs,], type="response"))    observed <- dat[whichobs, strsplit(paste(model$formula), "~")[[2]]]    error <- error + mean(observed != (fitted>cutoff))/K         ### in cv.glm the actual error is calculated as (y - p(y=1))     # error <- error + mean((observed - fitted)^2)/K     ### the mis-classification rate will depend on     ### how we decide what is assigned to each category   }  error}set.seed(1)cv_class(K=k, dat = data_train, model = fit)# Or# 1. Cross validation on the actual mis-classification ratecost_function <- function(y, yhat){  # misclassification rate on cutoff  mean((y != (yhat>0.5)))} # 2. CV boot::cv.glm(data=df, model= fit, K = k, cost = cost_function)# This uses the error calculated as (y - p(y=1)) # error <- error + mean((observed - fitted)^2)/K set.seed(1)boot::cv.glm(data=data_train, model= fit, K = k)## Metricspredicted <- ifelse(predict(fit,                             newdata=dataset_tst,                             type="response") > cutoff, 1, 0)actual <- dataset_tst$target# Misclassificationget_misclassification <- function(predicted, dataset, target){  mean(predicted != dataset_tst$target)}# Confusion Matrixmake_conf_mat <- function(predicted, actual) {  table(predicted = predicted, actual = actual)}# Ortable(as.numeric(predict(fitTot, type = "response") > 0.5),dex2$fail)# Sensitivity # TPR = Sens = TP/P = TP/(TP+FN) = 1-FNR# Note that this function is good for illustrative purposes, # but is easily broken. (Think about what happens if there are # no "positives" predicted.)# Specificity# TNR = Spec = TN/N = TN/(TN+FP) = 1-FPR### Accuracy# Acc = TP+TN/TP + TN + FP + FN = 1 - MISCmean(spam_tst_pred == spam_tst$type)mean(as.numeric(predict(fitTot, type = "response") > 0.5) == dex2$fail)### Misclassification rate on Conf Matrix# Misc = FP+FN/TP + TN + FP + FN = 1 - ACCmean(as.numeric(predict(fitTot, type = "response") > 0.5) != dex2$fail)# Prevalence# Prev = P/ #Observations = TP + FN/ #ObservationspredictedBinary <- ifelse(predict(fit2, newdata = testData, type = "response") > 0.5, "predBanck", "predNot")table(predictedBinary, testData$Banks)7 /20# Dummy variables (n-1)dex1$Sposato <- ifelse(dex1$SCivile == '1', 1, 0)