{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data And Web Mining Theory\n",
    "\n",
    "## Summary\n",
    "\n",
    "- Train e Test\n",
    "- Classificazione e Regressione\n",
    "- Supervised Learning\n",
    "- Knn\n",
    "    - Weight Knn\n",
    "-  Decision Trees\n",
    "    - Classificazione\n",
    "        - Binary Decision Trees\n",
    "        - Driving Factor, Leaf Node, Internal Node\n",
    "        - Gain and Gini\n",
    "        - Multiple classes\n",
    "        - Stop: Max Leaf, Max Depth\n",
    "        - Tuning\n",
    "    - Regression\n",
    "        - Leaf Node, Internal Node\n",
    "    - Model Overfitting\n",
    "    - Model Selection, Pruning\n",
    "- Linear Regression\n",
    "    - Large Polynomial Degree\n",
    "    - Feature Engeneering Choose\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "    - Non Linearly Separable Problems\n",
    "    - Non-Linear Support Vector Classifier\n",
    "- Validation Set\n",
    "    - K-fold Cross Validation\n",
    "    - Stratified Sampling\n",
    "    - Automatic Parameter Tuning\n",
    "- Bias e Variance\n",
    "    - Bagging\n",
    "    - Boosting\n",
    "        - AdaBoost\n",
    "    - Underfitting e Overfitting\n",
    "- Random Forest\n",
    "    - Similarity Estimator\n",
    "    - Missing Values Imputation\n",
    "- Ensemble Methods\n",
    "- Feature Selection\n",
    "    - Recursive Elimination\n",
    "    - Map to 0-1\n",
    "    - One-Hot Encoding\n",
    "    - Missing Values\n",
    "    - Confusion Matrix\n",
    "    - Receiver Operating Characteristic (ROC)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62aefeb02cdae29d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Train e Test\n",
    "\n",
    "Il concetto di \"Train e Test\" è fondamentale nell'ambito del machine learning. Quando affrontiamo problemi di previsione o classificazione utilizzando algoritmi di machine learning, dobbiamo garantire che il nostro modello sia in grado di generalizzare bene su dati non ancora visti. In altre parole, vogliamo che il modello sia in grado di fare previsioni accurate su nuovi dati che non sono stati utilizzati durante il processo di addestramento.\n",
    "\n",
    "Per farlo, suddividiamo il nostro dataset in due parti principali: il set di addestramento (Train) e il set di test. Il set di addestramento è utilizzato per insegnare al modello come effettuare previsioni, mentre il set di test è utilizzato per valutare le prestazioni del modello.\n",
    "\n",
    "La suddivisione dei dati è un passaggio critico in questo processo. Dobbiamo assicurarci che i dati nel set di test siano rappresentativi e indipendenti dai dati di addestramento. Ciò significa che i dati di test dovrebbero essere scelti in modo casuale e non dovrebbero essere stati utilizzati nel processo di addestramento del modello. Questo aiuta a evitare il cosiddetto \"overfitting,\" in cui il modello si adatta troppo bene ai dati di addestramento ma non generalizza bene su nuovi dati.\n",
    "\n",
    "La suddivisione dei dati in set di addestramento e test ha diversi scopi:\n",
    "\n",
    "1 - Valutazione delle prestazioni del modello: Utilizzando il set di test, possiamo valutare quanto bene il nostro modello si comporta su nuovi dati. Questo ci permette di stimare l'accuratezza delle previsioni.\n",
    "2 - Prevenzione dell'overfitting: Addestrare il modello su tutti i dati può portare a un'alta precisione sui dati di addestramento ma può generare modelli che non generalizzano bene. La suddivisione dei dati ci aiuta a rilevare se il modello sta sovradattando i dati di addestramento.\n",
    "3 - Selezione del modello migliore: Possiamo sperimentare diversi modelli e selezionare quello che funziona meglio utilizzando i dati di test.\n",
    "\n",
    "Esempio:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1461e15cb5a4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d12faf7bc18a8d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una volta addestrato il modello sul set di addestramento, puoi utilizzare il set di test per valutare le sue prestazioni."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61a194e8cc64250"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Classificazione e Regressione\n",
    "\n",
    "Nel contesto del machine learning, due delle principali categorie di problemi che possiamo affrontare sono la \"Classificazione\" e la \"Regressione.\" Questi concetti sono fondamentali per comprendere come applicare gli algoritmi di machine learning in vari scenari.\n",
    "\n",
    "Classificazione\n",
    "\n",
    "La classificazione è un tipo di problema in cui l'obiettivo è assegnare un'etichetta o una categoria a un oggetto o un insieme di dati in base alle sue caratteristiche. Ad esempio, potremmo voler classificare gli e-mail come spam o non spam, o riconoscere il genere di una persona in base alle sue caratteristiche fisiche.\n",
    "\n",
    "Per affrontare problemi di classificazione, vengono utilizzati algoritmi di apprendimento supervisionato. Questi algoritmi apprendono da un set di dati di addestramento in cui ogni esempio è associato a un'etichetta di classe conosciuta. Alcuni esempi di algoritmi di classificazione comuni includono la Regressione Logistica, gli Alberi Decisionali e le Support Vector Machines (SVM).\n",
    "\n",
    "Regressione\n",
    "\n",
    "La regressione è un tipo di problema in cui l'obiettivo è prevedere un valore numerico in base alle caratteristiche dell'oggetto o dei dati. Ad esempio, potremmo voler prevedere il prezzo di una casa in base alle sue dimensioni, alla posizione e ad altre caratteristiche.\n",
    "\n",
    "Anche in questo caso, gli algoritmi di regressione operano nell'ambito dell'apprendimento supervisionato. Utilizzano dati di addestramento in cui ogni esempio è associato a un valore target numerico noto. Alcuni esempi di algoritmi di regressione includono la Regressione Lineare, i Regressori Polinomiali e le Foreste Casuali.\n",
    "\n",
    "La principale differenza tra classificazione e regressione risiede nel tipo di output che ciascun problema mira a prevedere. Nella classificazione, cerchiamo di prevedere una categoria o una classe, mentre nella regressione, cerchiamo di prevedere un valore numerico continuo.\n",
    "\n",
    "In entrambi i casi, l'obiettivo è addestrare un modello che possa fare previsioni accurate su nuovi dati non visti. La scelta tra classificazione e regressione dipenderà dalla natura del problema che stai affrontando e dal tipo di output che desideri ottenere.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d75c1bf31950b6ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Supervised Learning\n",
    "\n",
    "Supervised Learning (Apprendimento Supervisionato) è uno dei paradigmi fondamentali del machine learning. Si tratta di un approccio in cui un modello viene addestrato per fare previsioni o prendere decisioni basandosi su dati di addestramento etichettati. In altre parole, il modello apprende da esempi conosciuti in cui si conoscono sia le caratteristiche (input) che le etichette (output).\n",
    "\n",
    "Ecco come funziona il Supervised Learning:\n",
    "\n",
    "Dati di Addestramento: Nel Supervised Learning, iniziamo con un dataset di addestramento, che è un insieme di esempi. Ogni esempio è costituito da un insieme di caratteristiche (features) che descrivono l'input e da un'etichetta che rappresenta l'output desiderato. Ad esempio, se stiamo cercando di addestrare un modello per riconoscere gatti e cani in immagini, il dataset di addestramento conterrà immagini di gatti e cani, ognuna etichettata come \"gatto\" o \"cane.\".\n",
    "\n",
    "Addestramento del Modello: Utilizzando il dataset di addestramento, addestriamo un modello di machine learning. L'obiettivo del modello è imparare una relazione tra le caratteristiche di input e le etichette di output in modo da poter fare previsioni accurate su nuovi dati.\n",
    "\n",
    "Previsioni su Nuovi Dati: Una volta addestrato il modello, possiamo usarlo per fare previsioni su nuovi dati, per i quali non conosciamo l'etichetta corretta. Il modello applicherà la conoscenza acquisita durante l'addestramento per effettuare previsioni.\n",
    "\n",
    "Valutazione delle Prestazioni: Per valutare le prestazioni del modello, confrontiamo le previsioni effettuate dal modello sui nuovi dati con le etichette reali, se disponibili. Le metriche di valutazione comuni includono l'accuratezza, la precisione, il richiamo, l'F1-score e altre metriche specifiche per il tipo di problema (classificazione o regressione)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abf7ea8234c5b536"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Knn\n",
    "\n",
    "Il K-Nearest Neighbors (Knn) è un semplice algoritmo di apprendimento supervisionato utilizzato per la classificazione e la regressione. Il principio di base di Knn è che gli oggetti che sono simili sono più propensi a condividere etichette simili. L'idea chiave è quella di calcolare la distanza tra un punto di dati di test e i punti di dati del set di addestramento e quindi assegnare all'oggetto di test l'etichetta della maggioranza dei punti più vicini (i \"vicini più prossimi\").\n",
    "\n",
    "Ecco come funziona Knn:\n",
    "\n",
    "- Calcolo delle Distanze: Per un dato oggetto di test, calcoliamo la distanza tra questo oggetto e tutti gli oggetti del set di addestramento. Le distanze comuni includono la distanza euclidea e la distanza di Manhattan.\n",
    "- Selezione dei K Vicini: Scegliamo i \"K\" oggetti di addestramento più vicini all'oggetto di test in base alle distanze calcolate.\n",
    "- Classificazione o Regressione: Per il caso della classificazione, assegniamo all'oggetto di test l'etichetta di classe più comune tra i K vicini. Per la regressione, calcoliamo la media (o un'altra aggregazione) delle etichette dei K vicini.\n",
    "\n",
    "Esempio:\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d08f13b36f58370"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza del modello Knn: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carica il dataset Iris come esempio\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Suddivisione dei dati in set di addestramento e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Addestramento del modello Knn\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Previsioni su dati di test\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Valutazione delle prestazioni\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuratezza del modello Knn:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T21:11:36.274071Z",
     "start_time": "2023-11-06T21:11:33.788516Z"
    }
   },
   "id": "c20e5b2bc6ea547c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Weighted Knn\n",
    "\n",
    "Il Weighted K-Nearest Neighbors (Weighted Knn) è una variante del Knn in cui si assegna un peso diverso ai punti di dati più vicini in base alla loro distanza dall'oggetto di test. In altre parole, i punti più vicini hanno un'influenza maggiore sul risultato rispetto ai punti più lontani. Questo è utile quando non tutti i punti vicini sono ugualmente rilevanti per la previsione.\n",
    "\n",
    "Esempio:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66febbda3a9ca6a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza del modello Weighted Knn: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carica il dataset Iris come esempio\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Suddivisione dei dati in set di addestramento e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Addestramento del modello Weighted Knn\n",
    "weighted_knn_model = KNeighborsClassifier(n_neighbors=3, weights='distance')  # Utilizza il parametro 'weights' per impostare la distanza come peso\n",
    "weighted_knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Previsioni su dati di test\n",
    "y_pred_weighted = weighted_knn_model.predict(X_test)\n",
    "\n",
    "# Valutazione delle prestazioni\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "print(\"Accuratezza del modello Weighted Knn:\", accuracy_weighted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T21:12:17.460483Z",
     "start_time": "2023-11-06T21:12:17.391557Z"
    }
   },
   "id": "8980bf1031d9aa4e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nell'esempio sopra, noterai che abbiamo impostato il parametro weights='distance' quando abbiamo creato il modello Weighted Knn. Questo significa che i punti più vicini riceveranno un peso maggiore, mentre i punti più lontani avranno un peso minore.\n",
    "\n",
    "Differenze:\n",
    "\n",
    "- Knn assegna lo stesso peso a tutti i punti vicini.\n",
    "- Weighted Knn assegna pesi diversi basati sulla distanza.\n",
    "- Weighted Knn è più flessibile e può fornire risultati migliori quando alcuni punti vicini sono più informativi di altri.\n",
    "\n",
    "In generale, l'uso del Weighted Knn è appropriato quando si sa che alcuni punti dati vicini sono più affidabili di altri per la previsione."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7138e3c07d8d3695"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Trees"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f05a518a77f34b76"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
